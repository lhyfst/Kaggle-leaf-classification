{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T20:59:32.149423Z",
     "start_time": "2018-06-23T20:59:25.408145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training data...\n",
      "Training data loaded!\n",
      "Creating Data Augmenter...\n",
      "Finished making data augmenter...\n",
      "Creating the model...\n",
      "Model created!\n",
      "Training model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All input arrays (x) should have the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9964262a5d6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m                               \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_num_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                               callbacks=[best_model])\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading the best model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liheyuan/ENV/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1501\u001b[0m                                  str(validation_data))\n\u001b[1;32m   1502\u001b[0m             val_x, val_y, val_sample_weights = self._standardize_user_data(\n\u001b[0;32m-> 1503\u001b[0;31m                 val_x, val_y, val_sample_weight)\n\u001b[0m\u001b[1;32m   1504\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liheyuan/ENV/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1039\u001b[0m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                           in zip(y, sample_weights, class_weights, self.sample_weight_modes)]\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m         \u001b[0mcheck_loss_and_target_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_output_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liheyuan/ENV/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mcheck_array_lengths\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mset_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         raise ValueError('All input arrays (x) should have '\n\u001b[0m\u001b[1;32m    180\u001b[0m                          'the same number of samples.')\n\u001b[1;32m    181\u001b[0m     \u001b[0mset_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All input arrays (x) should have the same number of samples."
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "# 参数\n",
    "model_idx = 10\n",
    "length_per_contour=200\n",
    "contours_data = '../middata/contours_data.npy'\n",
    "root = '../rawdata'\n",
    "\n",
    "\n",
    "split_random_state = 7\n",
    "split = .9\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator, array_to_img\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, Flatten, Input, merge, Reshape, Convolution1D, MaxPooling1D\n",
    "\n",
    "from generate_contour_data_and_augment import load_contours\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_numeric_training(standardize=True):\n",
    "    data = pd.read_csv(os.path.join(root, 'train.csv'))\n",
    "    ID = data.pop('id')\n",
    "    y = data.pop('species')\n",
    "    y = LabelEncoder().fit(y).transform(y)\n",
    "    X = StandardScaler().fit(data).transform(data) if standardize else data.values\n",
    "\n",
    "    return ID, X, y\n",
    "\n",
    "\n",
    "def load_numeric_test(standardize=True):\n",
    "    test = pd.read_csv(os.path.join(root, 'test.csv'))\n",
    "    ID = test.pop('id')\n",
    "    test = StandardScaler().fit(test).transform(test) if standardize else test.values\n",
    "    return ID, test\n",
    "\n",
    "\n",
    "def resize_img(img, max_dim=96):\n",
    "    \"\"\"\n",
    "    如果图片放歪了或者放倒了，将其扶正\n",
    "    \"\"\"\n",
    "    # Get the axis with the larger dimension\n",
    "    max_ax = max((0, 1), key=lambda i: img.size[i])\n",
    "    # Scale both axes so the image's largest dimension is max_dim\n",
    "    scale = max_dim / float(img.size[max_ax])\n",
    "    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))\n",
    "\n",
    "\n",
    "def load_image_data(ids, max_dim=96, center=True):\n",
    "    \"\"\"\n",
    "    将所有的图片统一成96x96大小\n",
    "    \"\"\"\n",
    "    X = np.empty((len(ids), max_dim, max_dim, 1))\n",
    "    for i, idee in enumerate(ids):\n",
    "        x = resize_img(load_img(os.path.join(root, 'images', str(idee) + '.jpg'), grayscale=True), max_dim=max_dim)\n",
    "        x = img_to_array(x)\n",
    "        length = x.shape[0]\n",
    "        width = x.shape[1]\n",
    "        if center:\n",
    "            h1 = int((max_dim - length) / 2)\n",
    "            h2 = h1 + length\n",
    "            w1 = int((max_dim - width) / 2)\n",
    "            w2 = w1 + width\n",
    "        else:\n",
    "            h1, w1 = 0, 0\n",
    "            h2, w2 = (length, width)\n",
    "        X[i, h1:h2, w1:w2, 0:1] = x\n",
    "    return np.around(X / 255.0)\n",
    "\n",
    "# def load_contours(ID):\n",
    "#     \"\"\"目前这是个假的加载函数，仅仅为了调试加上边缘数据后的代码能否跑通\"\"\"\n",
    "#     length = len(ID)\n",
    "#     return np.array([[0] * 100] * length)\n",
    "\n",
    "def fool_load_shape_and_blade_data_list(id_list):\n",
    "    length = len(id_list)\n",
    "    tmp = np.array([[[0] * 511] * 2] * length)\n",
    "#     return tmp[:,0,:], tmp[:,1,:]\n",
    "    return tmp[:,0,:]\n",
    "\n",
    "\n",
    "def load_train_data(split=split, random_state=None):\n",
    "    ID, X_num_tr, y = load_numeric_training()\n",
    "    X_img_tr = load_image_data(ID)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, train_size=split, random_state=random_state)\n",
    "    train_ind, test_ind = next(sss.split(X_num_tr, y, ID))\n",
    "    X_num_val, X_img_val, y_val, ID_val = X_num_tr[test_ind], X_img_tr[test_ind], y[test_ind], ID[test_ind]\n",
    "    X_num_tr, X_img_tr, y_tr, ID_tr = X_num_tr[train_ind], X_img_tr[train_ind], y[train_ind], ID[train_ind]\n",
    "    \n",
    "    contours_tr = load_contours(ID_tr, contours_data)\n",
    "    shape_contours_tr = fool_load_shape_and_blade_data_list(ID_tr)\n",
    "    contours_val = load_contours(ID_val, contours_data)\n",
    "    shape_contours_val = fool_load_shape_and_blade_data_list(ID_val)\n",
    "    return (X_num_tr, X_img_tr, y_tr, contours_tr, shape_contours_tr), (X_num_val, X_img_val, y_val, contours_val, shape_contours_val)\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    ID, X_num_te = load_numeric_test()\n",
    "    X_img_te = load_image_data(ID)\n",
    "    contours_test = load_contours(ID, contours_data)\n",
    "    shape_contours_test = fool_load_shape_and_blade_data_list(ID)\n",
    "    return ID, X_num_te, X_img_te, contours_test, shape_contours_test\n",
    "\n",
    "# 加载数据\n",
    "print('Loading the training data...')\n",
    "(X_num_tr, X_img_tr, y_tr, contours_tr, shape_contours_tr), (X_num_val, X_img_val, y_val, contours_val, shape_contours_val) = \\\n",
    "                                    load_train_data(random_state=split_random_state)\n",
    "y_tr_cat = to_categorical(y_tr)\n",
    "y_val_cat = to_categorical(y_val)\n",
    "print('Training data loaded!')\n",
    "\n",
    "\n",
    "class ImageDataGenerator2(ImageDataGenerator):\n",
    "    \"\"\"图像数据生成器\"\"\"\n",
    "    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n",
    "             save_to_dir=None, save_prefix='', save_format='jpeg'):\n",
    "        return NumpyArrayIterator2(\n",
    "            X, y, self,\n",
    "            batch_size=batch_size, shuffle=shuffle, seed=seed,\n",
    "            dim_ordering=self.dim_ordering,\n",
    "            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)\n",
    "\n",
    "\n",
    "class NumpyArrayIterator2(NumpyArrayIterator):\n",
    "    \"\"\"预提取数据生成器\"\"\"\n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            self.index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]))\n",
    "\n",
    "        for i, j in enumerate(self.index_array):\n",
    "            x = self.x[j]\n",
    "            x = self.image_data_generator.random_transform(x.astype('float32'))\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "        if self.save_to_dir:\n",
    "            for i in range(current_batch_size):\n",
    "                img = array_to_img(batch_x[i], self.dim_ordering, scale=True)\n",
    "                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n",
    "                                                                  index=current_index + i,\n",
    "                                                                  hash=np.random.randint(1e4),\n",
    "                                                                  format=self.save_format)\n",
    "                img.save(os.path.join(self.save_to_dir, fname))\n",
    "        if self.y is None:\n",
    "            return batch_x\n",
    "        batch_y = self.y[self.index_array]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "print('Creating Data Augmenter...')\n",
    "imgen = ImageDataGenerator2(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest')\n",
    "imgen_train = imgen.flow(X_img_tr, y_tr_cat, seed=np.random.randint(1, 10000))\n",
    "print('Finished making data augmenter...')\n",
    "\n",
    "\n",
    "def combined_model():\n",
    "\n",
    "    # 图像二维卷积模块\n",
    "    image_input = Input(shape=(96, 96, 1), name='image')\n",
    "    \n",
    "    x = Convolution2D(64, 5, 5, input_shape=(96, 96, 1), border_mode='same')(image_input)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    x = (Convolution2D(128, 5, 5, border_mode='same'))(x)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # 预选取特征MLP模块\n",
    "    numerical_input = Input(shape=(192,), name='numerical')\n",
    "    \n",
    "    numerical = Dense(128 ,activation='relu')(numerical_input)\n",
    "    \n",
    "    \n",
    "    # 预选取特征一维卷积模块\n",
    "    conv1d = (Reshape((64,3)))(numerical_input)\n",
    "    conv1d = Convolution1D(nb_filter=64, filter_length=4, border_mode='same')(conv1d)\n",
    "    conv1d = (Activation('relu'))(conv1d)\n",
    "    conv1d = (MaxPooling1D(pool_length=2, stride=2, border_mode='same'))(conv1d)\n",
    "    \n",
    "    conv1d = Convolution1D(nb_filter=128, filter_length=4, border_mode='same')(conv1d)\n",
    "    conv1d = (Activation('relu'))(conv1d)\n",
    "    conv1d = (MaxPooling1D(pool_length=2, stride=2, border_mode='same'))(conv1d)\n",
    "\n",
    "    conv1d = Flatten()(conv1d)\n",
    "    \n",
    "#     # 对轮廓线进行一维卷积\n",
    "    contour_input = Input(shape=(length_per_contour,2), name='contour')\n",
    "    \n",
    "    contour = (Reshape((length_per_contour,2)))(contour_input)\n",
    "    contour = Convolution1D(nb_filter=64, filter_length=4, border_mode='same')(contour)\n",
    "    contour = (Activation('relu'))(contour)\n",
    "    contour = (MaxPooling1D(pool_length=2, stride=2, border_mode='same'))(contour)\n",
    "    \n",
    "    contour = Convolution1D(nb_filter=128, filter_length=4, border_mode='same')(contour)\n",
    "    contour = (Activation('relu'))(contour)\n",
    "    contour = (MaxPooling1D(pool_length=2, stride=2, border_mode='same'))(contour)\n",
    "\n",
    "    contour = Flatten()(contour)\n",
    "    \n",
    "    # 对形状轮廓进行一维卷积\n",
    "    shape_contour_input = Input(shape=(511,2), name='shape_contour_input')\n",
    "    \n",
    "#     shape_contour = (Reshape((length_per_contour,2)))(shape_contour_input)\n",
    "    shape_contour = Convolution1D(nb_filter=64, filter_length=4, border_mode='same')(shape_contour_input)\n",
    "    shape_contour = (Activation('relu'))(shape_contour)\n",
    "    shape_contour = (MaxPooling1D(pool_length=2, stride=2, border_mode='same'))(shape_contour)\n",
    "    \n",
    "    shape_contour = Convolution1D(nb_filter=128, filter_length=4, border_mode='same')(shape_contour)\n",
    "    shape_contour = (Activation('relu'))(shape_contour)\n",
    "    shape_contour = (MaxPooling1D(pool_length=2, stride=2, border_mode='same'))(shape_contour)\n",
    "\n",
    "    shape_contour = Flatten()(shape_contour)\n",
    "    \n",
    "    \n",
    "    # 特征合并\n",
    "    concatenated = merge([x, numerical,conv1d, contour,shape_contour], mode='concat')\n",
    "#     concatenated = merge([x, numerical,conv1d], mode='concat')\n",
    "#     concatenated = contour\n",
    "\n",
    "\n",
    "    # dense层\n",
    "#     concatenated = Dense(1024, activation='relu')(concatenated)\n",
    "#     concatenated = Dropout(.5)(concatenated)\n",
    "\n",
    "    concatenated = Dense(512, activation='relu')(concatenated)\n",
    "    concatenated = Dropout(.5)(concatenated)\n",
    "    \n",
    "    # 输出\n",
    "    out = Dense(99, activation='softmax')(concatenated)\n",
    "\n",
    "    \n",
    "    model = Model(input=[image_input, numerical_input, contour_input, shape_contour_input], output=out)\n",
    "#     model = Model(input=[image_input, numerical_input], output=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "print('Creating the model...')\n",
    "model = combined_model()\n",
    "print('Model created!')\n",
    "\n",
    "\n",
    "\n",
    "def combined_generator(imgen, X, contours, shape_contours):\n",
    "    \"\"\"\n",
    "    各种数据的综合生成器\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for i in range(X.shape[0]):\n",
    "            batch_img, batch_y = next(imgen)\n",
    "            x = X[imgen.index_array]\n",
    "            contour = contours[imgen.index_array]\n",
    "            shape_contour = shape_contours[imgen.index_array]\n",
    "#             yield [batch_img, x, contour], batch_y\n",
    "            yield [batch_img, x, contour, shape_contour], batch_y\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "# autosave best Model\n",
    "best_model_file = \"../models/leafnet_\"+str(model_idx)+\".h5\"\n",
    "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "print('Training model...')\n",
    "history = model.fit_generator(combined_generator(imgen_train, X_num_tr, contours_tr, shape_contours_tr),\n",
    "                              samples_per_epoch=X_num_tr.shape[0],\n",
    "                              nb_epoch=89,\n",
    "                              validation_data=([X_img_val, X_num_val, contours_val, shape_contours_tr], y_val_cat),\n",
    "#                               validation_data=([X_img_val, X_num_val], y_val_cat),\n",
    "                              nb_val_samples=X_num_val.shape[0],\n",
    "                              verbose=0,\n",
    "                              callbacks=[best_model])\n",
    "\n",
    "print('Loading the best model...')\n",
    "model = load_model(best_model_file)\n",
    "print('Best Model loaded!')\n",
    "\n",
    "\n",
    "# 预测测试集并生成可提交文件\n",
    "LABELS = sorted(pd.read_csv(os.path.join(root, 'train.csv')).species.unique())\n",
    "index, X_num_te, X_img_te, contours_test, shape_contours_test = load_test_data()  # index就是ID\n",
    "yPred_proba = model.predict([X_img_te,  X_num_te, contours_test, shape_contours_test])\n",
    "# yPred_proba = model.predict([X_img_te,  X_num_te])\n",
    "\n",
    "yPred = pd.DataFrame(yPred_proba,index=index,columns=LABELS)\n",
    "\n",
    "print('Creating and writing submission...')\n",
    "fp = open('../submissions/Keras_ConvNet_with_pictures_kernel_'+str(model_idx)+'.csv', 'w')\n",
    "fp.write(yPred.to_csv())\n",
    "print('Finished writing submission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T05:32:17.749296Z",
     "start_time": "2018-06-18T05:32:17.543024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[batch_img, x], batch_y = next(combined_generator(imgen_train, X_num_tr))\n",
    "\n",
    "tmp_img = batch_img[0].reshape((96,96))\n",
    "\n",
    "plot_images_data(tmp_img.flatten(),tmp_img.flatten(),figsize=(5,5),hue=False,hue_time=15,show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T12:32:56.939547Z",
     "start_time": "2018-06-20T12:32:56.802020Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4bb65ee4d734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mbatch_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgen_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_num_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtmp_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_images_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhue_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_generator' is not defined"
     ]
    }
   ],
   "source": [
    "[batch_img, x], batch_y = next(combined_generator(imgen_train, X_num_tr))\n",
    "\n",
    "tmp_img = batch_img[0].reshape((96,96))\n",
    "\n",
    "plot_images_data(tmp_img.flatten(),tmp_img.flatten(),figsize=(5,5),hue=False,hue_time=15,show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T05:21:29.582173Z",
     "start_time": "2018-06-18T05:21:29.550465Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 –*-\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "def plot_images_data(images_data_a,images_data_b,figsize=(5,5),hue=False,hue_time=15,show=True):\n",
    "    \"\"\"\n",
    "    将两个一维array,(pixel*pixel),生成图像，用于观察\n",
    "    若想观察单个dateset，设置images_data_a==images_data_b即可\n",
    "    save_path: 保存路径，形如 '../images/tmp.png'\n",
    "    hue代表是否考虑色度\n",
    "    \"\"\"\n",
    "    pixel = int(round(np.sqrt(images_data_a.shape[0])))\n",
    "    \n",
    "    if not show:\n",
    "        mpl.use('Agg')\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if not hue:\n",
    "        tmp_0 = images_data_a*225\n",
    "        tmp_1 = images_data_b*225\n",
    "        tmp_2 = np.zeros(pixel**2)\n",
    "    else:\n",
    "        tmp_0 = images_data_a*hue_time\n",
    "        tmp_1 = images_data_b*hue_time\n",
    "        tmp_2 = np.zeros(pixel**2)\n",
    "    \n",
    "    tmp = np.stack((tmp_0,tmp_1,tmp_2),axis=0)\n",
    "    tmp = tmp.reshape((3,pixel,pixel))\n",
    "    \n",
    "    r = Image.fromarray(tmp[0]).convert('L')\n",
    "    g = Image.fromarray(tmp[1]).convert('L')\n",
    "    b = Image.fromarray(tmp[2]).convert('L')\n",
    "    image = Image.merge(\"RGB\", (r, g, b))\n",
    "    \n",
    "    f = plt.figure(figsize=figsize)\n",
    "    plt.imshow(image)\n",
    "#     plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
