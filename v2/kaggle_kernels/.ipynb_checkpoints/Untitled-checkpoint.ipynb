{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-17T20:08:21.499462Z",
     "start_time": "2018-06-17T20:08:16.354210Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liheyuan/ENV/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training data...\n",
      "Training data loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liheyuan/ENV/local/lib/python2.7/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# If you want to use Theano, all you need to change\n",
    "# is the dim ordering whenever you are dealing with\n",
    "# the image array. Instead of\n",
    "# (samples, rows, cols, channels) it should be\n",
    "# (samples, channels, rows, cols)\n",
    "\n",
    "# Keras stuff\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# A large amount of the data loading code is based on najeebkhan's kernel\n",
    "# Check it out at https://www.kaggle.com/najeebkhan/leaf-classification/neural-network-through-keras\n",
    "root = '../rawdata'\n",
    "np.random.seed(2016)\n",
    "split_random_state = 7\n",
    "split = .9\n",
    "\n",
    "\n",
    "def load_numeric_training(standardize=True):\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted features for the training data\n",
    "    and returns a tuple of the image ids, the data, and the labels\n",
    "    \"\"\"\n",
    "    # Read data from the CSV file\n",
    "    data = pd.read_csv(os.path.join(root, 'train.csv'))\n",
    "    ID = data.pop('id')\n",
    "\n",
    "    # Since the labels are textual, so we encode them categorically\n",
    "    y = data.pop('species')\n",
    "    y = LabelEncoder().fit(y).transform(y)\n",
    "    # standardize the data by setting the mean to 0 and std to 1\n",
    "    X = StandardScaler().fit(data).transform(data) if standardize else data.values\n",
    "\n",
    "    return ID, X, y\n",
    "\n",
    "\n",
    "def load_numeric_test(standardize=True):\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted features for the test data\n",
    "    and returns a tuple of the image ids, the data\n",
    "    \"\"\"\n",
    "    test = pd.read_csv(os.path.join(root, 'test.csv'))\n",
    "    ID = test.pop('id')\n",
    "    # standardize the data by setting the mean to 0 and std to 1\n",
    "    test = StandardScaler().fit(test).transform(test) if standardize else test.values\n",
    "    return ID, test\n",
    "\n",
    "\n",
    "def resize_img(img, max_dim=96):\n",
    "    \"\"\"\n",
    "    Resize the image to so the maximum side is of size max_dim\n",
    "    Returns a new image of the right size\n",
    "    \"\"\"\n",
    "    # Get the axis with the larger dimension\n",
    "    max_ax = max((0, 1), key=lambda i: img.size[i])\n",
    "    # Scale both axes so the image's largest dimension is max_dim\n",
    "    scale = max_dim / float(img.size[max_ax])\n",
    "    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))\n",
    "\n",
    "\n",
    "def load_image_data(ids, max_dim=96, center=True):\n",
    "    \"\"\"\n",
    "    Takes as input an array of image ids and loads the images as numpy\n",
    "    arrays with the images resized so the longest side is max-dim length.\n",
    "    If center is True, then will place the image in the center of\n",
    "    the output array, otherwise it will be placed at the top-left corner.\n",
    "    \"\"\"\n",
    "    # Initialize the output array\n",
    "    # NOTE: Theano users comment line below and\n",
    "    X = np.empty((len(ids), max_dim, max_dim, 1))\n",
    "    # X = np.empty((len(ids), 1, max_dim, max_dim)) # uncomment this\n",
    "    for i, idee in enumerate(ids):\n",
    "        # Turn the image into an array\n",
    "        x = resize_img(load_img(os.path.join(root, 'images', str(idee) + '.jpg'), grayscale=True), max_dim=max_dim)\n",
    "        x = img_to_array(x)\n",
    "        # Get the corners of the bounding box for the image\n",
    "        # NOTE: Theano users comment the two lines below and\n",
    "        length = x.shape[0]\n",
    "        width = x.shape[1]\n",
    "        # length = x.shape[1] # uncomment this\n",
    "        # width = x.shape[2] # uncomment this\n",
    "        if center:\n",
    "            h1 = int((max_dim - length) / 2)\n",
    "            h2 = h1 + length\n",
    "            w1 = int((max_dim - width) / 2)\n",
    "            w2 = w1 + width\n",
    "        else:\n",
    "            h1, w1 = 0, 0\n",
    "            h2, w2 = (length, width)\n",
    "        # Insert into image matrix\n",
    "        # NOTE: Theano users comment line below and\n",
    "        X[i, h1:h2, w1:w2, 0:1] = x\n",
    "        # X[i, 0:1, h1:h2, w1:w2] = x  # uncomment this\n",
    "    # Scale the array values so they are between 0 and 1\n",
    "    return np.around(X / 255.0)\n",
    "\n",
    "\n",
    "def load_train_data(split=split, random_state=None):\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted feature and image training data and\n",
    "    splits them into training and cross-validation.\n",
    "    Returns one tuple for the training data and one for the validation\n",
    "    data. Each tuple is in the order pre-extracted features, images,\n",
    "    and labels.\n",
    "    \"\"\"\n",
    "    # Load the pre-extracted features\n",
    "    ID, X_num_tr, y = load_numeric_training()\n",
    "    # Load the image data\n",
    "    X_img_tr = load_image_data(ID)\n",
    "    # Split them into validation and cross-validation\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, train_size=split, random_state=random_state)\n",
    "    train_ind, test_ind = next(sss.split(X_num_tr, y))\n",
    "    X_num_val, X_img_val, y_val = X_num_tr[test_ind], X_img_tr[test_ind], y[test_ind]\n",
    "    X_num_tr, X_img_tr, y_tr = X_num_tr[train_ind], X_img_tr[train_ind], y[train_ind]\n",
    "    return (X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val)\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted feature and image test data.\n",
    "    Returns a tuple in the order ids, pre-extracted features,\n",
    "    and images.\n",
    "    \"\"\"\n",
    "    # Load the pre-extracted features\n",
    "    ID, X_num_te = load_numeric_test()\n",
    "    # Load the image data\n",
    "    X_img_te = load_image_data(ID)\n",
    "    return ID, X_num_te, X_img_te\n",
    "\n",
    "print('Loading the training data...')\n",
    "(X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val) = load_train_data(random_state=split_random_state)\n",
    "y_tr_cat = to_categorical(y_tr)\n",
    "y_val_cat = to_categorical(y_val)\n",
    "print('Training data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-17T20:42:39.229685Z",
     "start_time": "2018-06-17T20:42:39.129453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Data Augmenter...\n",
      "Finished making data augmenter...\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator, array_to_img\n",
    "\n",
    "# A little hacky piece of code to get access to the indices of the images\n",
    "# the data augmenter is working with.\n",
    "class ImageDataGenerator2(ImageDataGenerator):\n",
    "    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n",
    "             save_to_dir=None, save_prefix='', save_format='jpeg'):\n",
    "        return NumpyArrayIterator2(\n",
    "            X, y, self,\n",
    "            batch_size=batch_size, shuffle=shuffle, seed=seed,\n",
    "            data_format = self.data_format,\n",
    "#             dim_ordering=self.dim_ordering,\n",
    "#             dim_ordering = 'default',\n",
    "            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)\n",
    "\n",
    "\n",
    "class NumpyArrayIterator2(NumpyArrayIterator):     \n",
    "    def _flow_index(self):\n",
    "        # Ensure self.batch_index is 0.\n",
    "        self.reset()\n",
    "        while 1:\n",
    "            if self.seed is not None:\n",
    "                np.random.seed(self.seed + self.total_batches_seen)\n",
    "            if self.batch_index == 0:\n",
    "                self._set_index_array()\n",
    "  \n",
    "            current_index = (self.batch_index * self.batch_size) % self.n\n",
    "            if self.n > current_index + self.batch_size:\n",
    "                self.batch_index += 1\n",
    "            else:\n",
    "                self.batch_index = 0\n",
    "            self.total_batches_seen += 1\n",
    "        yield self.index_array[current_index:current_index + self.batch_size],current_index, self.batch_size\n",
    "    def next(self):\n",
    "        # for python 2.x.\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch\n",
    "        # see http://anandology.com/blog/using-iterators-and-generators/\n",
    "        with self.lock:\n",
    "            # We changed index_array to self.index_array\n",
    "            print next(self.index_generator)\n",
    "            tmp = next(self.index_generator)\n",
    "            \n",
    "            self.index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock so it can be done in parallel\n",
    "        batch_x = np.zeros(tuple([current_batch_size] + list(self.X.shape)[1:]))\n",
    "        for i, j in enumerate(self.index_array):\n",
    "            x = self.X[j]\n",
    "            x = self.image_data_generator.random_transform(x.astype('float32'))\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "        if self.save_to_dir:\n",
    "            for i in range(current_batch_size):\n",
    "#                 img = array_to_img(batch_x[i], self.dim_ordering, scale=True)\n",
    "                img = array_to_img(batch_x[i], self.data_format, scale=True)\n",
    "                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n",
    "                                                                  index=current_index + i,\n",
    "                                                                  hash=np.random.randint(1e4),\n",
    "                                                                  format=self.save_format)\n",
    "                img.save(os.path.join(self.save_to_dir, fname))\n",
    "        if self.y is None:\n",
    "            return batch_x\n",
    "        batch_y = self.y[self.index_array]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "print('Creating Data Augmenter...')\n",
    "imgen = ImageDataGenerator2(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest')\n",
    "imgen_train = imgen.flow(X_img_tr, y_tr_cat, seed=np.random.randint(1, 10000))\n",
    "print('Finished making data augmenter...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-17T20:42:43.958240Z",
     "start_time": "2018-06-17T20:42:43.809171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n",
      "Model created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liheyuan/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (5, 5), padding=\"same\", input_shape=(96, 96, 1...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/liheyuan/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), padding=\"same\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/liheyuan/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:24: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/liheyuan/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, Flatten, Input, merge\n",
    "\n",
    "\n",
    "def combined_model():\n",
    "\n",
    "    # Define the image input\n",
    "    image = Input(shape=(96, 96, 1), name='image')\n",
    "    # Pass it through the first convolutional layer\n",
    "    x = Convolution2D(8, 5, 5, input_shape=(96, 96, 1), border_mode='same')(image)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Now through the second convolutional layer\n",
    "    x = (Convolution2D(32, 5, 5, border_mode='same'))(x)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Flatten our array\n",
    "    x = Flatten()(x)\n",
    "    # Define the pre-extracted feature input\n",
    "    numerical = Input(shape=(192,), name='numerical')\n",
    "    # Concatenate the output of our convnet with our pre-extracted feature input\n",
    "    concatenated = merge([x, numerical], mode='concat')\n",
    "\n",
    "    # Add a fully connected layer just like in a normal MLP\n",
    "    x = Dense(100, activation='relu')(concatenated)\n",
    "    x = Dropout(.5)(x)\n",
    "\n",
    "    # Get the final output\n",
    "    out = Dense(99, activation='softmax')(x)\n",
    "    # How we create models with the Functional API\n",
    "    model = Model(input=[image, numerical], output=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "print('Creating the model...')\n",
    "model = combined_model()\n",
    "print('Model created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-17T20:42:45.170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liheyuan/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:39: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/liheyuan/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., verbose=0, validation_data=([array([[..., steps_per_epoch=891, epochs=89, callbacks=[<keras.ca..., validation_steps=99)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def combined_generator(imgen, X):\n",
    "    \"\"\"\n",
    "    A generator to train our keras neural network. It\n",
    "    takes the image augmenter generator and the array\n",
    "    of the pre-extracted features.\n",
    "    It yields a minibatch and will run indefinitely\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for i in range(X.shape[0]):\n",
    "            # Get the image batch and labels\n",
    "#             batch_img, batch_y = next(imgen)\n",
    "#             print '++++++++++++++++'\n",
    "            batch_img, batch_y = next(imgen)\n",
    "#             print next(imgen)\n",
    "#             tmp = next(imgen)\n",
    "#             print '++++++++++++++++'\n",
    "            # This is where that change to the source code we\n",
    "            # made will come in handy. We can now access the indicies\n",
    "            # of the images that imgen gave us.\n",
    "            x = X[imgen.index_array]\n",
    "            yield [batch_img, x], batch_y\n",
    "\n",
    "# autosave best Model\n",
    "best_model_file = \"leafnet.h5\"\n",
    "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "print('Training model...')\n",
    "history = model.fit_generator(\n",
    "    combined_generator(imgen_train, X_num_tr),\n",
    "                              samples_per_epoch=X_num_tr.shape[0],\n",
    "                              nb_epoch=89,\n",
    "                              validation_data=([X_img_val, X_num_val], y_val_cat),\n",
    "                              nb_val_samples=X_num_val.shape[0],\n",
    "                              verbose=0,\n",
    "                              callbacks=[best_model]\n",
    "                             )\n",
    "\n",
    "print('Loading the best model...')\n",
    "model = load_model(best_model_file)\n",
    "print('Best Model loaded!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
